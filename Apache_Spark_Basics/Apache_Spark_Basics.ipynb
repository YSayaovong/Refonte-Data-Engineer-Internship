{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUA-ViI95UeS",
        "outputId": "f014ed65-b5ff-4c31-c1e8-ab0abb75f8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark #install pyspark (force)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Configure Spark Application\n",
        "conf = SparkConf().setAppName(\"Apache Spark Basics\").setMaster(\"local[*]\")  # Use all CPU cores\n",
        "sc = SparkContext(conf=conf)  # Create a Spark Context\n",
        "\n",
        "# Video logs data\n",
        "video_logs = [\n",
        "    \"user1,video1,play\",\n",
        "    \"user2,video2,pause\",\n",
        "    \"user1,video1,stop\",\n",
        "    \"user3,video3,play\",\n",
        "    \"user2,video2,play\",\n",
        "]\n",
        "\n",
        "# Parallelize the video logs (create an RDD)\n",
        "logs_rdd = sc.parallelize(video_logs)\n",
        "\n",
        "# Transformations and Actions\n",
        "# Step 1: Parse the log lines into structured tuples (user, video, action)\n",
        "parsed_logs = logs_rdd.map(lambda log: tuple(log.split(\",\")))\n",
        "\n",
        "# Step 2: Filter logs for a specific action (e.g., \"play\")\n",
        "play_logs = parsed_logs.filter(lambda log: log[2] == \"play\")\n",
        "\n",
        "# Step 3: Count occurrences of each video being \"played\"\n",
        "video_play_count = (\n",
        "    play_logs.map(lambda log: (log[1], 1))  # Map each video play to (video, 1)\n",
        "    .reduceByKey(lambda x, y: x + y)  # Reduce by key to count plays per video\n",
        ")\n",
        "\n",
        "# Step 4: Collect the results to display\n",
        "result = video_play_count.collect()\n",
        "\n",
        "# Print the results\n",
        "print(\"Video Play Counts:\")\n",
        "for video, count in result:\n",
        "    print(f\"{video}: {count} times\")\n",
        "\n",
        "# Stop the Spark Context\n",
        "sc.stop()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmf1GiHW5hke",
        "outputId": "dff6b66e-c4ca-4e1b-dedb-15c8f6cf7f3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Play Counts:\n",
            "video1: 1 times\n",
            "video3: 1 times\n",
            "video2: 1 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLm9chYz7imo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}